#!/usr/bin/env python3
"""
WAF æ€§èƒ½å‹åŠ›æµ‹è¯•è„šæœ¬ - å¢å¼ºç‰ˆ
æ”¯æŒå¤§ä½“ç§¯è¯·æ±‚å’Œ HTTPS
"""

import requests
import time
import threading
import json
import statistics
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

class WAFPerformanceTester:
    def __init__(self, base_url, host_header, port=80, use_https=False):
        self.protocol = "https" if use_https else "http"
        self.base_url = f"{self.protocol}://{base_url}:{port}"
        self.host_header = host_header
        self.session = requests.Session()
        # å¿½ç•¥ SSL è¯ä¹¦éªŒè¯
        self.session.verify = False
        # ç¦ç”¨ä¸å®‰å…¨è¯·æ±‚è­¦å‘Š
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        self.headers = {
            'Host': host_header,
            'User-Agent': 'WAF-Performance-Tester/1.0',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Content-Type': 'application/x-www-form-urlencoded'
        }
        self.results = {
            'test_time': datetime.now().isoformat(),
            'throughput_metrics': [],
            'latency_metrics': [],
            'concurrency_metrics': []
        }

    def generate_large_payload(self, size_kb=1):
        """ç”ŸæˆæŒ‡å®šå¤§å°çš„è¯·æ±‚ä½“"""
        # åŸºç¡€æ•°æ®
        base_data = {
            "username": "test_user_12345",
            "email": "test.user@example.com",
            "description": "This is a test payload for WAF performance testing. ",
            "metadata": {
                "timestamp": int(time.time()),
                "session_id": "session_abcdefghijklmnopqrstuvwxyz",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        }
        
        # é‡å¤åŸºç¡€æ•°æ®ç›´åˆ°è¾¾åˆ°ç›®æ ‡å¤§å°
        payload = base_data.copy()
        current_size = len(json.dumps(payload))
        
        # æ·»åŠ å¡«å……æ•°æ®
        filler_text = "x" * 100  # 100å­—èŠ‚çš„å¡«å……å—
        while current_size < size_kb * 1024:
            payload[f"filler_{int(time.time()*1000)}"] = filler_text
            current_size = len(json.dumps(payload))
            
        return json.dumps(payload)

    def make_normal_request(self, path="/", method="GET", payload_size_kb=1):
        """å‘é€æ­£å¸¸è¯·æ±‚æµ‹é‡æ€§èƒ½"""
        try:
            if method.upper() == "GET":
                # GET è¯·æ±‚ï¼šåœ¨ URL å‚æ•°ä¸­æ·»åŠ æ•°æ®
                params = {"data": self.generate_large_payload(payload_size_kb)[:1000]}  # URL å‚æ•°é™åˆ¶
                start_time = time.time()
                response = self.session.get(
                    f"{self.base_url}{path}",
                    headers=self.headers,
                    params=params,
                    timeout=10
                )
            else:
                # POST è¯·æ±‚ï¼šåœ¨è¯·æ±‚ä½“ä¸­æ·»åŠ æ•°æ®
                data = self.generate_large_payload(payload_size_kb)
                start_time = time.time()
                response = self.session.post(
                    f"{self.base_url}{path}",
                    headers=self.headers,
                    data={"payload": data},
                    timeout=10
                )
            
            end_time = time.time()
            response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            return {
                'status_code': response.status_code,
                'response_time': response_time,
                'success': True,
                'content_length': len(response.content),
                'request_size': len(data) if method.upper() == "POST" else len(str(params))
            }
        except Exception as e:
            return {
                'status_code': 0,
                'response_time': 0,
                'success': False,
                'error': str(e),
                'request_size': 0
            }

    def calculate_percentile(self, data, percentile):
        """æ‰‹åŠ¨è®¡ç®—ç™¾åˆ†ä½æ•°ï¼ˆä¸ä¾èµ–numpyï¼‰"""
        if not data:
            return 0
        
        sorted_data = sorted(data)
        index = (len(sorted_data) - 1) * percentile / 100
        lower_index = int(index)
        upper_index = lower_index + 1
        
        if upper_index >= len(sorted_data):
            return sorted_data[lower_index]
        
        weight = index - lower_index
        return sorted_data[lower_index] * (1 - weight) + sorted_data[upper_index] * weight

    def throughput_test(self, duration=60, requests_per_second=100, payload_size_kb=1, method="GET"):
        """ååé‡æµ‹è¯•ï¼šå›ºå®šæ—¶é—´å†…çš„è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        print(f"ğŸš€ å¼€å§‹ååé‡æµ‹è¯•: {duration}ç§’, {requests_per_second}è¯·æ±‚/ç§’, {payload_size_kb}KB/è¯·æ±‚, {method}æ–¹æ³•")
        
        total_requests = 0
        successful_requests = 0
        response_times = []
        total_request_size = 0
        start_time = time.time()
        
        while time.time() - start_time < duration:
            batch_start = time.time()
            batch_success = 0
            batch_size = 0
            
            # å‘é€ä¸€æ‰¹è¯·æ±‚
            with ThreadPoolExecutor(max_workers=min(requests_per_second, 200)) as executor:
                futures = [
                    executor.submit(
                        self.make_normal_request, 
                        "/test", 
                        method, 
                        payload_size_kb
                    ) for _ in range(requests_per_second)
                ]
                
                for future in as_completed(futures):
                    result = future.result()
                    total_requests += 1
                    total_request_size += result.get('request_size', 0)
                    
                    if result['success']:
                        successful_requests += 1
                        batch_success += 1
                        response_times.append(result['response_time'])
                        batch_size += result.get('request_size', 0)
            
            # æ§åˆ¶è¯·æ±‚é€Ÿç‡
            batch_time = time.time() - batch_start
            if batch_time < 1.0:
                time.sleep(1.0 - batch_time)
        
        # è®¡ç®—æŒ‡æ ‡
        actual_duration = time.time() - start_time
        throughput = successful_requests / actual_duration
        avg_response_time = statistics.mean(response_times) if response_times else 0
        error_rate = (total_requests - successful_requests) / total_requests * 100
        bandwidth_mbps = (total_request_size * 8) / (actual_duration * 1000000)  # Mbps
        
        metrics = {
            'duration': actual_duration,
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'throughput_rps': throughput,
            'avg_response_time_ms': avg_response_time,
            'error_rate_percent': error_rate,
            'p95_response_time_ms': self.calculate_percentile(response_times, 95),
            'payload_size_kb': payload_size_kb,
            'method': method,
            'total_data_mb': total_request_size / (1024 * 1024),
            'bandwidth_mbps': bandwidth_mbps
        }
        
        self.results['throughput_metrics'].append(metrics)
        print(f"âœ… ååé‡æµ‹è¯•å®Œæˆ: {throughput:.2f} RPS, å¹³å‡å»¶è¿Ÿ: {avg_response_time:.2f}ms, "
              f"é”™è¯¯ç‡: {error_rate:.2f}%, å¸¦å®½: {bandwidth_mbps:.2f} Mbps")
        return metrics

    def concurrency_test(self, max_concurrent_users=1000, test_duration=30, payload_size_kb=1):
        """å¹¶å‘ç”¨æˆ·æµ‹è¯•"""
        print(f"ğŸ‘¥ å¼€å§‹å¹¶å‘æµ‹è¯•: {max_concurrent_users}å¹¶å‘ç”¨æˆ·, {test_duration}ç§’, {payload_size_kb}KB/è¯·æ±‚")
        
        response_times = []
        success_count = 0
        total_requests = 0
        total_request_size = 0
        lock = threading.Lock()
        
        def concurrent_worker(worker_id):
            nonlocal success_count, total_requests, total_request_size
            start_time = time.time()
            while time.time() - start_time < test_duration:
                # äº¤æ›¿ä½¿ç”¨ GET å’Œ POST æ–¹æ³•
                method = "POST" if worker_id % 2 == 0 else "GET"
                result = self.make_normal_request("/test", method, payload_size_kb)
                with lock:
                    total_requests += 1
                    total_request_size += result.get('request_size', 0)
                    if result['success']:
                        success_count += 1
                        response_times.append(result['response_time'])
        
        # åˆ›å»ºå¹¶å‘ç”¨æˆ·
        threads = []
        for i in range(min(max_concurrent_users, 500)):  # é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°
            thread = threading.Thread(target=concurrent_worker, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æµ‹è¯•å®Œæˆ
        for thread in threads:
            thread.join()
        
        # è®¡ç®—æŒ‡æ ‡
        throughput = success_count / test_duration
        avg_response_time = statistics.mean(response_times) if response_times else 0
        error_rate = (total_requests - success_count) / total_requests * 100
        bandwidth_mbps = (total_request_size * 8) / (test_duration * 1000000)
        
        metrics = {
            'concurrent_users': max_concurrent_users,
            'duration': test_duration,
            'throughput_rps': throughput,
            'avg_response_time_ms': avg_response_time,
            'error_rate_percent': error_rate,
            'total_requests': total_requests,
            'successful_requests': success_count,
            'payload_size_kb': payload_size_kb,
            'total_data_mb': total_request_size / (1024 * 1024),
            'bandwidth_mbps': bandwidth_mbps
        }
        
        self.results['concurrency_metrics'].append(metrics)
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ: {throughput:.2f} RPS, å¹³å‡å»¶è¿Ÿ: {avg_response_time:.2f}ms, "
              f"å¸¦å®½: {bandwidth_mbps:.2f} Mbps")
        return metrics

    def latency_stability_test(self, requests_count=1000, payload_size_kb=1):
        """å»¶è¿Ÿç¨³å®šæ€§æµ‹è¯•"""
        print(f"â±ï¸  å¼€å§‹å»¶è¿Ÿç¨³å®šæ€§æµ‹è¯•: {requests_count}æ¬¡è¯·æ±‚, {payload_size_kb}KB/è¯·æ±‚")
        
        response_times = []
        success_count = 0
        request_sizes = []
        
        for i in range(requests_count):
            if i % 100 == 0:
                print(f"è¿›åº¦: {i}/{requests_count}")
                
            # äº¤æ›¿ä½¿ç”¨ä¸åŒæ–¹æ³•
            method = "POST" if i % 3 == 0 else "GET"
            result = self.make_normal_request("/test", method, payload_size_kb)
            if result['success']:
                success_count += 1
                response_times.append(result['response_time'])
                request_sizes.append(result.get('request_size', 0))
            
            # æ·»åŠ å°å»¶è¿Ÿé¿å…è¿‡è½½
            if i % 50 == 0:
                time.sleep(0.05)
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total_data_mb = sum(request_sizes) / (1024 * 1024)
        
        metrics = {
            'requests_count': requests_count,
            'success_count': success_count,
            'min_latency_ms': min(response_times) if response_times else 0,
            'max_latency_ms': max(response_times) if response_times else 0,
            'avg_latency_ms': statistics.mean(response_times) if response_times else 0,
            'p50_latency_ms': self.calculate_percentile(response_times, 50),
            'p95_latency_ms': self.calculate_percentile(response_times, 95),
            'p99_latency_ms': self.calculate_percentile(response_times, 99),
            'payload_size_kb': payload_size_kb,
            'total_data_mb': total_data_mb
        }
        
        # è®¡ç®—æ ‡å‡†å·®
        if response_times:
            avg = metrics['avg_latency_ms']
            variance = sum((x - avg) ** 2 for x in response_times) / len(response_times)
            metrics['std_latency_ms'] = variance ** 0.5
        else:
            metrics['std_latency_ms'] = 0
        
        self.results['latency_metrics'].append(metrics)
        print(f"âœ… å»¶è¿Ÿç¨³å®šæ€§æµ‹è¯•å®Œæˆ: å¹³å‡{metrics['avg_latency_ms']:.2f}ms, P95: {metrics['p95_latency_ms']:.2f}ms, "
              f"æ€»æ•°æ®é‡: {total_data_mb:.2f} MB")
        return metrics

    def mixed_workload_test(self, duration=120):
        """æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•"""
        print(f"ğŸ”„ å¼€å§‹æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•: {duration}ç§’")
        
        def mixed_worker(worker_id):
            response_times = []
            success_count = 0
            
            start_time = time.time()
            while time.time() - start_time < duration:
                # éšæœºé€‰æ‹©è´Ÿè½½å¤§å°å’Œæ–¹æ³•
                payload_size = random.choice([1, 2, 5, 10])  # 1KB, 2KB, 5KB, 10KB
                method = random.choice(["GET", "POST"])
                
                result = self.make_normal_request("/test", method, payload_size)
                if result['success']:
                    success_count += 1
                    response_times.append(result['response_time'])
                
                # éšæœºå»¶è¿Ÿ
                time.sleep(random.uniform(0.01, 0.1))
            
            return response_times, success_count
        
        # åˆ›å»ºæ··åˆè´Ÿè½½å·¥ä½œçº¿ç¨‹
        workers = 50
        all_response_times = []
        total_success = 0
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [executor.submit(mixed_worker, i) for i in range(workers)]
            
            for future in as_completed(futures):
                times, success = future.result()
                all_response_times.extend(times)
                total_success += success
        
        throughput = total_success / duration
        avg_response_time = statistics.mean(all_response_times) if all_response_times else 0
        
        metrics = {
            'duration': duration,
            'throughput_rps': throughput,
            'avg_response_time_ms': avg_response_time,
            'total_requests': total_success,
            'p95_response_time_ms': self.calculate_percentile(all_response_times, 95),
            'test_type': 'mixed_workload'
        }
        
        self.results['throughput_metrics'].append(metrics)
        print(f"âœ… æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•å®Œæˆ: {throughput:.2f} RPS, å¹³å‡å»¶è¿Ÿ: {avg_response_time:.2f}ms")
        return metrics

    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
        print("ğŸ¯ å¼€å§‹å…¨é¢çš„ WAF æ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # 1. å»¶è¿Ÿç¨³å®šæ€§æµ‹è¯• - ä¸åŒè´Ÿè½½å¤§å°
        print("\nğŸ“Š é˜¶æ®µ1: å»¶è¿Ÿç¨³å®šæ€§æµ‹è¯•")
        for size in [1, 2, 5]:
            self.latency_stability_test(requests_count=300, payload_size_kb=size)
            time.sleep(2)
        
        # 2. ååé‡æµ‹è¯• - ä¸åŒè´Ÿè½½çº§åˆ«å’Œæ–¹æ³•
        print("\nğŸ“Š é˜¶æ®µ2: ååé‡æµ‹è¯•")
        throughput_configs = [
            (50, 1, "GET"), (100, 1, "GET"), 
            (50, 2, "POST"), (100, 2, "POST"),
            (30, 5, "POST"), (50, 5, "POST")
        ]
        
        for rps, size, method in throughput_configs:
            self.throughput_test(
                duration=25, 
                requests_per_second=rps, 
                payload_size_kb=size, 
                method=method
            )
            time.sleep(3)
        
        # 3. å¹¶å‘æµ‹è¯• - ä¸åŒå¹¶å‘çº§åˆ«
        print("\nğŸ“Š é˜¶æ®µ3: å¹¶å‘æµ‹è¯•")
        for users in [100, 200, 300]:
            self.concurrency_test(
                max_concurrent_users=users, 
                test_duration=25, 
                payload_size_kb=2
            )
            time.sleep(3)
        
        # 4. æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•
        print("\nğŸ“Š é˜¶æ®µ4: æ··åˆå·¥ä½œè´Ÿè½½æµ‹è¯•")
        self.mixed_workload_test(duration=90)
        
        # 5. é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
        print("\nğŸ“Š é˜¶æ®µ5: é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•")
        self.throughput_test(
            duration=120, 
            requests_per_second=80, 
            payload_size_kb=2, 
            method="POST"
        )
        
        self.generate_report()

    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("ğŸ“Š WAF æ€§èƒ½æµ‹è¯•æŠ¥å‘Š - å¢å¼ºç‰ˆ")
        print("=" * 70)
        
        report = {
            'test_configuration': {
                'target_url': self.base_url,
                'host_header': self.host_header,
                'protocol': self.protocol,
                'test_time': self.results['test_time']
            },
            'performance_summary': {}
        }
        
        # æ±‡æ€»ååé‡æ•°æ®
        if self.results['throughput_metrics']:
            throughputs = [m['throughput_rps'] for m in self.results['throughput_metrics']]
            bandwidths = [m.get('bandwidth_mbps', 0) for m in self.results['throughput_metrics']]
            
            report['performance_summary']['max_throughput_rps'] = max(throughputs)
            report['performance_summary']['avg_throughput_rps'] = statistics.mean(throughputs)
            report['performance_summary']['max_bandwidth_mbps'] = max(bandwidths) if bandwidths else 0
        
        # æ±‡æ€»å»¶è¿Ÿæ•°æ®
        if self.results['latency_metrics']:
            latencies = [m['avg_latency_ms'] for m in self.results['latency_metrics']]
            p95_latencies = [m['p95_latency_ms'] for m in self.results['latency_metrics']]
            
            report['performance_summary']['avg_latency_ms'] = statistics.mean(latencies)
            report['performance_summary']['avg_p95_latency_ms'] = statistics.mean(p95_latencies)
        
        # æ‰“å°è¯¦ç»†æŠ¥å‘Š
        print(f"ğŸ æµ‹è¯•ç›®æ ‡: {self.base_url}")
        print(f"ğŸ¯ Hostå¤´éƒ¨: {self.host_header}")
        print(f"ğŸ”’ åè®®: {self.protocol.upper()}")
        
        if self.results['throughput_metrics']:
            print("\nğŸ“ˆ ååé‡æµ‹è¯•ç»“æœ:")
            for i, metric in enumerate(self.results['throughput_metrics']):
                bandwidth = metric.get('bandwidth_mbps', 0)
                payload = metric.get('payload_size_kb', 0)
                method = metric.get('method', 'GET')
                print(f"   æµ‹è¯•{i+1}: {metric['throughput_rps']:.1f} RPS, "
                      f"å»¶è¿Ÿ: {metric['avg_response_time_ms']:.1f}ms, "
                      f"é”™è¯¯ç‡: {metric['error_rate_percent']:.1f}%, "
                      f"å¸¦å®½: {bandwidth:.1f} Mbps, "
                      f"è´Ÿè½½: {payload}KB, æ–¹æ³•: {method}")
        
        if self.results['latency_metrics']:
            print(f"\nâ±ï¸  å»¶è¿Ÿåˆ†æ (å¤šè´Ÿè½½å¹³å‡):")
            print(f"   å¹³å‡å»¶è¿Ÿ: {report['performance_summary']['avg_latency_ms']:.1f}ms")
            print(f"   å¹³å‡P95å»¶è¿Ÿ: {report['performance_summary']['avg_p95_latency_ms']:.1f}ms")
        
        if self.results['concurrency_metrics']:
            print(f"\nğŸ‘¥ å¹¶å‘èƒ½åŠ›:")
            for metric in self.results['concurrency_metrics']:
                print(f"   {metric['concurrent_users']}ç”¨æˆ·: {metric['throughput_rps']:.1f} RPS, "
                      f"å¸¦å®½: {metric.get('bandwidth_mbps', 0):.1f} Mbps")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"waf_performance_report_{timestamp}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({**self.results, **report}, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return report

def main():
    parser = argparse.ArgumentParser(description='WAF æ€§èƒ½æµ‹è¯•å·¥å…· - å¢å¼ºç‰ˆ')
    parser.add_argument('--url', default='127.0.0.1', help='ç›®æ ‡URLæˆ–IPåœ°å€')
    parser.add_argument('--host', default='http.kabubu.com', help='Hostå¤´éƒ¨å€¼')
    parser.add_argument('--port', type=int, default=80, help='ç«¯å£å·')
    parser.add_argument('--https', action='store_true', help='ä½¿ç”¨HTTPSåè®®')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œæµ‹è¯•
    tester = WAFPerformanceTester(args.url, args.host, args.port, args.https)
    
    try:
        tester.run_comprehensive_test()
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    import random
    main()